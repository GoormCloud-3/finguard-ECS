# app.py
import json
import logging
import time
import boto3
import pandas as pd
import signal
import io
from botocore.config import Config

from aws_xray_sdk.core import xray_recorder, patch
from aws_xray_sdk.core.context import Context
from aws_xray_sdk.core.models.trace_header import TraceHeader

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê¸°ë³¸ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
region = "ap-northeast-2"

# ë„¤íŠ¸ì›Œí¬ ì•ˆì •í™”: ì¬ì‹œë„/íƒ€ì„ì•„ì›ƒ
_boto_cfg = Config(
    retries={"max_attempts": 10, "mode": "standard"},
    connect_timeout=5,
    read_timeout=65,  # SQS long polling(WaitTimeSeconds=20) ê³ ë ¤
)

# í´ë¼ì´ì–¸íŠ¸
ssm_client        = boto3.client("ssm",               region_name=region, config=_boto_cfg)
ddb_client        = boto3.client("dynamodb",          region_name=region, config=_boto_cfg)
sagemaker_client  = boto3.client("sagemaker-runtime", region_name=region, config=_boto_cfg)
sns_client        = boto3.client("sns",               region_name=region, config=_boto_cfg)
sqs_client        = boto3.client("sqs",               region_name=region, config=_boto_cfg)
s3_client        = boto3.client("s3",                region_name=region, config=_boto_cfg)


sageMakerEndpoint = None
topicArn          = None
tableName         = None
queue_url         = None
s3_bucket         = None
s3_key            = None
initialized       = False

# ì¢…ë£Œ ì‹ í˜¸
RUNNING = True
def _handle_sigterm(signum, frame):
    global RUNNING
    logging.info("ğŸ›‘ SIGTERM received, shutting down gracefully...")
    RUNNING = False

signal.signal(signal.SIGTERM, _handle_sigterm)
signal.signal(signal.SIGINT,  _handle_sigterm)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í—¬í¼ (ë°ì½”ë ˆì´í„° ì œê±°) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_param(name, with_decryption=False):
    # boto3 íŒ¨ì¹˜ ë•ë¶„ì— ìë™ subsegment ìƒì„±ë¨. ëª…ì‹œì ìœ¼ë¡œë„ ê°ìŒ€ ìˆ˜ ìˆìŒ.
    with xray_recorder.in_subsegment("ssm:get_parameter"):
        logging.info("ğŸ” Fetching SSM parameter: %s (with_decryption=%s)", name, with_decryption)
        resp = ssm_client.get_parameter(Name=name, WithDecryption=with_decryption)
        return resp['Parameter']['Value']

def init():
    """í•„ìˆ˜ íŒŒë¼ë¯¸í„° ë¡œë”© (ë¶€ëª¨ ì„¸ê·¸ë¨¼íŠ¸ ë‚´ì—ì„œ í˜¸ì¶œ í•„ìš”)"""
    logging.info("ğŸ”§ Initializing SQS service...")
    global sageMakerEndpoint, topicArn, tableName, queue_url, s3_bucket, s3_key, initialized
    if initialized:
        return

    try:
        # ê°ê° ë‚´ë¶€ì—ì„œ ssm subsegmentê°€ ìë™/ëª…ì‹œì ìœ¼ë¡œ ì—´ë¦¼
        sageMakerEndpoint = get_param("/finguard/dev/finance/fraud_sage_maker_endpoint_name")
        topicArn          = get_param("/finguard/dev/finance/alert_sns_topic")
        tableName         = get_param("/finguard/dev/finance/notification_table_name")
        queue_url         = get_param("/finguard/dev/finance/trade_queue_host")
        s3_bucket         = get_param("/finguard/dev/finance/model_s3_bucket")
        s3_key            = get_param("/finguard/dev/finance/model_s3_key")

        if not all([sageMakerEndpoint, topicArn, tableName, queue_url]):
            logging.error("âŒ One or more SSM parameters are empty.")
            raise ValueError("One or more SSM parameters are empty.")
        if not queue_url.startswith("https://"):
            logging.warning("âš ï¸ queue_url doesn't look like a full URL: %s", queue_url)

        initialized = True
        logging.info("âœ… Initialized: endpoint=%s, topic=%s, table=%s, queue=%s, s3_bucket=%s, s3_key=%s",
                     sageMakerEndpoint, topicArn, tableName, queue_url, s3_bucket, s3_key)
    except Exception:
        logging.exception("âŒ Initialization failed")
        # ì»¨í…Œì´ë„ˆ ì¢…ë£Œ ë°©ì§€: ìƒìœ„ì—ì„œ ì¬ì‹œë„
        time.sleep(10)

def get_fcm_tokens(user_sub: str):
    with xray_recorder.in_subsegment("ddb:get_fcm_tokens"):
        logging.info("ğŸ” Retrieving FCM tokens for user: %s", user_sub)
        resp = ddb_client.get_item(
            TableName=tableName,
            Key={'user_id': {'S': user_sub}},
            ProjectionExpression='fcmTokens'
        )
        tokens = []
        if 'Item' in resp and 'fcmTokens' in resp['Item']:
            tokens = [t['S'] for t in resp['Item']['fcmTokens']['L']]
        logging.info("âœ… FCM tokens: %s", tokens)
        return tokens

def invoke_sagemaker(endpoint: str, features):
    with xray_recorder.in_subsegment("sagemaker:invoke_endpoint"):
        logging.info("ğŸ“¡ Calling SageMaker endpoint: %s", endpoint)
        response = sagemaker_client.invoke_endpoint(
            EndpointName=endpoint,
            ContentType='application/json',
            Body=json.dumps({'features': features})
        )
        result_str = response['Body'].read().decode()
        try:
            result = json.loads(result_str)
        except json.JSONDecodeError:
            logging.error("âŒ Invalid JSON from SageMaker: %s", result_str)
            raise
        logging.info("âœ… SageMaker response: %s", result)
    # --S3ì— features ì¬í•™ìŠµìš© csv ì €ì¥--
    # ---- S3ì— ëˆ„ì  ì €ì¥ ----
    global s3_bucket, s3_key

    # 1. ê¸°ì¡´ CSV ë‹¤ìš´ë¡œë“œ
    try:
        obj = s3_client.get_object(Bucket=s3_bucket, Key=s3_key)
        df_existing = pd.read_csv(io.BytesIO(obj['Body'].read()))
        logging.info("ğŸ“¥ Existing features loaded from s3://%s/%s", s3_bucket, s3_key)
    except s3_client.exceptions.NoSuchKey:
        df_existing = pd.DataFrame()  # íŒŒì¼ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        logging.info("â„¹ï¸ No existing features file at s3://%s/%s, starting fresh", s3_bucket, s3_key)

    # 2. ìƒˆë¡œìš´ featuresë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
    df_new = pd.DataFrame([features])  # featuresê°€ dictë¼ ê°€ì •

    # 3. ê¸°ì¡´ + ìƒˆ features í•©ì¹˜ê¸°
    df_total = pd.concat([df_existing, df_new], ignore_index=True)

    # 4. ë‹¤ì‹œ CSVë¡œ ì €ì¥
    csv_buffer = io.StringIO()
    df_total.to_csv(csv_buffer, index=False)
    s3_client.put_object(Bucket=s3_bucket, Key=s3_key, Body=csv_buffer.getvalue())
    logging.info("ğŸ“¤ Features saved to s3://%s/%s", s3_bucket, s3_key)
    
    return result
    
def _build_trace_header() -> str:
    """
    X-Ray ì „íŒŒ í—¤ë” í˜•ì‹: "Root=1-...;Parent=...;Sampled=1|0"
    ê°€ëŠ¥í•˜ë©´ í˜„ì¬ subsegmentì˜ idë¥¼ Parentë¡œ ì‚¬ìš©.
    """
    ent = xray_recorder.current_subsegment() or xray_recorder.current_segment()
    if not ent:
        return ""
    root = ent.trace_id          # e.g. 1-6f21f3b1-5c7c3c5e3a9c1c0d2e1f0a9b
    parent = ent.id              # segment or subsegment id
    sampled = "1" if getattr(ent, "sampled", False) else "0"
    return f"Root={root};Parent={parent};Sampled={sampled}"

def publish_sns(fcm_tokens):
    with xray_recorder.in_subsegment("sns:publish"):
        logging.info("ğŸ”” Publishing SNS with tokens: %s", fcm_tokens)
        if not fcm_tokens:
            logging.info("â„¹ï¸ No FCM tokens. Skipping SNS publish.")
            return

        
        trace_header = _build_trace_header()  # âœ… ì „íŒŒ í—¤ë” ìƒì„±
        sns_client.publish(
            TopicArn=topicArn,
            Message=json.dumps({'fcmTokens': fcm_tokens}),
            MessageAttributes={
                'X-Amzn-Trace-Id': {
                    'DataType': 'String',
                    'StringValue': trace_header or '',
                }
            }
        )
        logging.info("âœ… SNS message published")

def receive_messages():
    with xray_recorder.in_subsegment("sqs:receive_messages"):
        logging.info("ğŸ“¥ Receiving messages from SQS queue: %s", queue_url)
        if not queue_url:
            logging.error("âŒ queue_url is not set. Cannot receive messages.")
            raise RuntimeError("queue_url is not set")
        response = sqs_client.receive_message(
            QueueUrl=queue_url,
            MaxNumberOfMessages=10,
            WaitTimeSeconds=20,
            MessageAttributeNames=['All'],
            AttributeNames=['All'],
            VisibilityTimeout=60
        )
        msgs = response.get('Messages', [])
        logging.info("ğŸ“¥ Received %d messages", len(msgs))
        return msgs

def delete_message(receipt_handle: str):
    with xray_recorder.in_subsegment("sqs:delete_message"):
        try:
            logging.info("ğŸ—‘ï¸ Deleting message")
            sqs_client.delete_message(QueueUrl=queue_url, ReceiptHandle=receipt_handle)
        except Exception:
            logging.exception("âŒ Failed to delete message")

def process_message(record: dict):
    """ë¹„ì¦ˆ ì²˜ë¦¬. í˜¸ì¶œí•˜ëŠ” ìª½ì—ì„œ ì„¸ê·¸ë¨¼íŠ¸/ì„œë¸Œì„¸ê·¸ë¨¼íŠ¸ ì—´ì–´ë‘”ë‹¤."""
    try:
        body = json.loads(record['Body']) if isinstance(record.get('Body'), str) else record['Body']
    except Exception:
        logging.exception("âŒ Invalid SQS message body")
        return
    logging.info("ğŸ“¬ Processing message: %s", body)

    try:
        message = json.loads(body.get('Message', body)) if isinstance(body.get('Message', body), str) else body.get('Message', body)
    except Exception:
        logging.exception("âŒ Invalid nested message (SNS-style)")
        return

    user_sub = (message or {}).get('userSub') or body.get('userSub')
    features = (message or {}).get('features') or body.get('features')
    if features is None:
        logging.warning("âš ï¸ Missing 'features' in message. Skipping.")
        return

    try:
        logging.info("ğŸ” Processing features for user: %s, features: %s", user_sub, features)
        result = invoke_sagemaker(sageMakerEndpoint, features)
        logging.info("âœ… SageMaker result: %s", result)

        if result.get('prediction') == 1:
            tokens = get_fcm_tokens(user_sub) if user_sub else []
            publish_sns(tokens)
            logging.info("âœ… Notification sent to user: %s tokens=%s", user_sub, tokens)
        else:
            logging.info("â„¹ï¸ No fraud detected for user: %s", user_sub)
    except Exception:
        logging.exception("âŒ Error during message processing")
        return

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë©”ì¸ ë£¨í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    # ë¡œê¹…
    logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s [%(name)s] %(message)s")
    logging.info("ğŸš€ SQS receive Worker started")

    # X-Ray ì´ˆê¸°í™” (ê°œë°œ ì¤‘ 100% ì¶”ì  ê¶Œì¥)
    xray_recorder.configure(
        service="sqs-service",
        context=Context(),
        sampling=False,           # â† ê°œë°œì—ì„œëŠ” ì „ë¶€ ê¸°ë¡
    )
    # boto3ë§Œ íŒ¨ì¹˜ (requests ë¯¸ì‚¬ìš© ì‹œ ì—ëŸ¬ ë°©ì§€)
    patch(('boto3',))

    # --- ì´ˆê¸°í™” ì¬ì‹œë„ ë£¨í”„: init í˜¸ì¶œì€ 'bootstrap:init' ì„¸ê·¸ë¨¼íŠ¸ ì•ˆì—ì„œ ---
    global initialized
    while not initialized and RUNNING:
        seg = xray_recorder.begin_segment("bootstrap:init")
        try:
            init()
        finally:
            xray_recorder.end_segment()
        if not initialized:
            time.sleep(5)

    # --- ë©”ì¸ í´ë§ ë£¨í”„ ---
    while RUNNING:
        try:
            # 1) ë©”ì‹œì§€ ìˆ˜ì‹ ì€ ë³„ë„ 'sqs:poll' ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ
            poll_seg = xray_recorder.begin_segment("sqs:poll")
            try:
                logging.info("ğŸ“¥ Polling SQS...")
                messages = receive_messages()
            finally:
                xray_recorder.end_segment()  # â˜… ìˆ˜ì‹ ë§Œ ê°ì‹¸ê³  ë°”ë¡œ ë‹«ëŠ”ë‹¤ (ì„¸ê·¸ë¨¼íŠ¸ ì¤‘ì²© ë°©ì§€)

            if not messages:
                time.sleep(1)
                continue

            logging.info("ğŸ“¥ Received %d messages to process", len(messages))

            # 2) ê° ë©”ì‹œì§€ëŠ” **ìê¸°ë§Œì˜ ì„¸ê·¸ë¨¼íŠ¸**ë¡œ ì²˜ë¦¬ (Trace í—¤ë” ìˆìœ¼ë©´ ì´ì–´ë¶™ì„)
            for msg in messages:
                attrs   = msg.get("MessageAttributes", {}) or {}
                hdr_val = (
                    (attrs.get("trace_header") or {}).get("StringValue")
                    or (attrs.get("X-Amzn-Trace-Id") or {}).get("StringValue")
                    or ""
                )

                # trace header íŒŒì‹±
                if hdr_val:
                    th = TraceHeader.from_header_str(hdr_val)
                    # ìƒˆ ì„¸ê·¸ë¨¼íŠ¸ (ìƒìœ„ poll ì„¸ê·¸ë¨¼íŠ¸ì™€ **ì¤‘ì²©ë˜ì§€ ì•ŠìŒ**)
                    xray_recorder.begin_segment(
                        name="sqs:process_message",
                        traceid=th.root,
                        parent_id=th.parent
                    )
                    is_subsegment = False
                else:
                    # í—¤ë” ì—†ìœ¼ë©´ ë…ë¦½ ì„¸ê·¸ë¨¼íŠ¸ë¡œë§Œ (ì¤‘ì²© ë°©ì§€ ìœ„í•´ subsegment ëŒ€ì‹  segment ê¶Œì¥)
                    xray_recorder.begin_segment("sqs:process_message")
                    is_subsegment = False

                try:
                    seg = xray_recorder.current_segment()
                    if seg:
                        seg.put_annotation("queue_url", queue_url or "")
                        seg.put_annotation("message_id", msg.get("MessageId", ""))

                    process_message(msg)
                    delete_message(msg["ReceiptHandle"])
                except Exception:
                    logging.exception("Error processing message")
                finally:
                    # ìœ„ì—ì„œ í•­ìƒ begin_segmentë¡œ ì—´ì—ˆìœ¼ë¯€ë¡œ end_segmentë¡œ ë‹«ëŠ”ë‹¤
                    xray_recorder.end_segment()

        except Exception:
            logging.exception("Error receiving messages")
            time.sleep(5)

    logging.info("ğŸ‘‹ Exiting main loop.")

if __name__ == "__main__":
    main()
