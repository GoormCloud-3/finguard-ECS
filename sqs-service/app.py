# app.py
import os
import json
import logging
import time
import signal
import io
import threading
from http.server import BaseHTTPRequestHandler, HTTPServer

import boto3
import pandas as pd
from botocore.config import Config

# OpenTelemetry
from opentelemetry import trace
from opentelemetry.trace import Status, StatusCode
from opentelemetry.propagate import extract
from opentelemetry.propagators.textmap import Getter

# Prometheus
from prometheus_client import Counter, Histogram
from prometheus_client import generate_latest, CONTENT_TYPE_LATEST

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê¸°ë³¸ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
region = os.getenv("AWS_REGION", "ap-northeast-2")

# ë„¤íŠ¸ì›Œí¬ ì•ˆì •í™”: ì¬ì‹œë„/íƒ€ì„ì•„ì›ƒ
_boto_cfg = Config(
    retries={"max_attempts": 10, "mode": "standard"},
    connect_timeout=5,
    read_timeout=65,  # SQS long polling ê³ ë ¤
)

# í´ë¼ì´ì–¸íŠ¸
ssm_client        = boto3.client("ssm",               region_name=region, config=_boto_cfg)
ddb_client        = boto3.client("dynamodb",          region_name=region, config=_boto_cfg)
sagemaker_client  = boto3.client("sagemaker-runtime", region_name=region, config=_boto_cfg)
sns_client        = boto3.client("sns",               region_name=region, config=_boto_cfg)
sqs_client        = boto3.client("sqs",               region_name=region, config=_boto_cfg)
s3_client         = boto3.client("s3",                region_name=region, config=_boto_cfg)
sts_client        = boto3.client("sts",               region_name=region, config=_boto_cfg)

sageMakerEndpoint = None
topicArn          = None
tableName         = None
queue_url         = None
s3_bucket         = None
s3_key            = None
initialized       = False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Prometheus Metrics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SQS_POLL_SIZE         = Histogram("sqs_poll_batch_size", "Messages received per poll", buckets=(0, 1, 2, 5, 10))
SQS_ERRORS_TOTAL      = Counter("sqs_errors_total", "Unhandled errors")
MSG_PROCESSED_TOTAL   = Counter("sqs_messages_processed_total", "Messages processed", ["result"])  # success|skipped|error
SM_INVOKE_SECONDS     = Histogram("sagemaker_invoke_seconds", "SageMaker invoke latency (s)")
S3_APPEND_SECONDS     = Histogram("s3_append_seconds", "S3 append latency (s)")
SNS_PUBLISH_TOTAL     = Counter("sns_publish_total", "SNS publishes (alerts)")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì¢…ë£Œ ì‹ í˜¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RUNNING = True
def _handle_sigterm(signum, frame):
    global RUNNING
    logging.info("ğŸ›‘ SIGTERM received, shutting down gracefully...")
    RUNNING = False

signal.signal(signal.SIGTERM, _handle_sigterm)
signal.signal(signal.SIGINT,  _handle_sigterm)

# OpenTelemetry Tracer
tracer = trace.get_tracer("sqs-service")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í—¬ìŠ¤/ë©”íŠ¸ë¦­ ì„œë²„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
HEALTH_PORT = int(os.getenv("HEALTH_PORT", "8000"))

class _Health(BaseHTTPRequestHandler):
    def do_GET(self):
        if self.path == "/health":
            self.send_response(200); self.end_headers(); self.wfile.write(b"ok")
        elif self.path == "/metrics":
            output = generate_latest()
            self.send_response(200)
            self.send_header("Content-Type", CONTENT_TYPE_LATEST)
            self.send_header("Content-Length", str(len(output)))
            self.end_headers()
            self.wfile.write(output)
        else:
            self.send_response(404); self.end_headers()

def _start_health_server():
    srv = HTTPServer(("0.0.0.0", HEALTH_PORT), _Health)
    threading.Thread(target=srv.serve_forever, daemon=True).start()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ Getter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class _AttrGetter(Getter):
    def get(self, carrier, key):
        if not carrier or not key:
            return []
        for k in (key, key.lower(), key.upper(), key.title()):
            if k in carrier:
                v = carrier[k]
                if v is None:
                    return []
                return [v] if isinstance(v, str) else [str(v)]
        return []
    def keys(self, carrier):
        return list(carrier.keys()) if carrier else []

def _extract_ctx_from_sqs(msg: dict):
    """
    SQS ë©”ì‹œì§€ì—ì„œ OTel/X-Ray ì»¨í…ìŠ¤íŠ¸ ë³µì›:
    - SQS MessageAttributes (traceparent, baggage, X-Amzn-Trace-Id ë“±)
    - SNS -> SQS ì¸ ê²½ìš° Body(SNS envelope)ì˜ MessageAttributes ë„ ê²€ì‚¬
    """
    carrier = {}

    # 1) SQS MessageAttributes: { Name : {DataType:String, StringValue: "..."} }
    attrs = (msg.get("MessageAttributes") or {})
    for k, v in attrs.items():
        if isinstance(v, dict) and "StringValue" in v:
            carrier[k] = v["StringValue"]

    # 2) SNS envelope ë‚´ë¶€ MessageAttributes
    try:
        body = json.loads(msg.get("Body") or "{}")
        if isinstance(body, dict):
            sns_attrs = body.get("MessageAttributes") or {}
            for k, v in sns_attrs.items():
                if isinstance(v, dict):
                    if "Value" in v:
                        carrier.setdefault(k, v["Value"])
                    elif "StringValue" in v:
                        carrier.setdefault(k, v["StringValue"])
    except Exception:
        pass

    # í‘œì¤€ í‚¤ ìš°ì„ 
    norm = {}
    for k, v in carrier.items():
        lk = k.lower()
        if lk in ("x-amzn-trace-id", "traceparent", "baggage"):
            norm[k] = v
    if not norm and carrier:
        norm = carrier

    # extract(carrier, getter=...)
    return extract(norm, getter=_AttrGetter())

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í—¬í¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_param(name, with_decryption=False):
    with tracer.start_as_current_span("ssm.get_parameter") as span:
        span.set_attribute("param.name", name)
        span.set_attribute("param.decrypt", with_decryption)
        resp = ssm_client.get_parameter(Name=name, WithDecryption=with_decryption)
        return resp["Parameter"]["Value"]

def init():
    """í•„ìˆ˜ íŒŒë¼ë¯¸í„° ë¡œë”©"""
    logging.info("ğŸ”§ Initializing SQS worker...")
    global sageMakerEndpoint, topicArn, tableName, queue_url, s3_bucket, s3_key, initialized
    if initialized:
        return
    try:
        with tracer.start_as_current_span("bootstrap.load_params"):
            sageMakerEndpoint = get_param("/finguard/dev/finance/fraud_sage_maker_endpoint_name")
            topicArn          = get_param("/finguard/dev/finance/alert_sns_topic")
            tableName         = get_param("/finguard/dev/finance/notification_table_name")
            queue_url         = get_param("/finguard/dev/finance/trade_queue_host")
            s3_bucket         = get_param("/finguard/dev/finance/model_s3_bucket")
            s3_key            = get_param("/finguard/dev/finance/model_s3_key")

            if not all([sageMakerEndpoint, topicArn, tableName, queue_url]):
                raise ValueError("One or more SSM parameters are empty.")
            if not queue_url.startswith("https://"):
                logging.warning("âš ï¸ queue_url doesn't look like full URL: %s", queue_url)

        initialized = True
        logging.info("âœ… Initialized: endpoint=%s, topic=%s, table=%s, queue=%s, s3_bucket=%s, s3_key=%s",
                     sageMakerEndpoint, topicArn, tableName, queue_url, s3_bucket, s3_key)
    except Exception:
        logging.exception("âŒ Initialization failed")
        time.sleep(10)  # ìƒìœ„ì—ì„œ ì¬ì‹œë„

def get_fcm_tokens(user_sub: str):
    with tracer.start_as_current_span("ddb.get_fcm_tokens") as span:
        span.set_attribute("user.sub", user_sub)
        resp = ddb_client.get_item(
            TableName=tableName,
            Key={"user_id": {"S": user_sub}},
            ProjectionExpression="fcmTokens",
        )
        tokens = []
        if "Item" in resp and "fcmTokens" in resp["Item"]:
            tokens = [t["S"] for t in resp["Item"]["fcmTokens"]["L"]]
        return tokens

def invoke_sagemaker(endpoint: str, features):
    with tracer.start_as_current_span("sagemaker.invoke_endpoint") as span, SM_INVOKE_SECONDS.time():
        span.set_attribute("sm.endpoint", endpoint)
        response = sagemaker_client.invoke_endpoint(
            EndpointName=endpoint,
            ContentType="application/json",
            Body=json.dumps({"features": features}),
        )
        result_str = response["Body"].read().decode()
        try:
            result = json.loads(result_str)
        except json.JSONDecodeError as e:
            span.record_exception(e)
            span.set_status(Status(StatusCode.ERROR, str(e)))
            raise

    # S3ì— features ì €ì¥(ëˆ„ì  CSV)
    with tracer.start_as_current_span("s3.append_features") as span, S3_APPEND_SECONDS.time():
        span.set_attribute("s3.bucket", s3_bucket or "")
        span.set_attribute("s3.key", s3_key or "")
        try:
            try:
                obj = s3_client.get_object(Bucket=s3_bucket, Key=s3_key)
                df_existing = pd.read_csv(io.BytesIO(obj["Body"].read()))
            except s3_client.exceptions.NoSuchKey:
                df_existing = pd.DataFrame()

            df_new = pd.DataFrame([features])
            df_total = pd.concat([df_existing, df_new], ignore_index=True)

            csv_buffer = io.StringIO()
            df_total.to_csv(csv_buffer, index=False)
            s3_client.put_object(Bucket=s3_bucket, Key=s3_key, Body=csv_buffer.getvalue())
        except Exception as e:
            span.record_exception(e)
            span.set_status(Status(StatusCode.ERROR, str(e)))
            # ì €ì¥ ì‹¤íŒ¨í•´ë„ ì¶”ë¡  ê²°ê³¼ëŠ” ë°˜í™˜
    return result

def publish_sns(fcm_tokens):
    with tracer.start_as_current_span("sns.publish") as span:
        span.set_attribute("sns.topic", topicArn or "")
        if not fcm_tokens:
            return
        sns_client.publish(
            TopicArn=topicArn,
            Message=json.dumps({"fcmTokens": fcm_tokens}),
        )
        SNS_PUBLISH_TOTAL.inc()

def receive_messages():
    with tracer.start_as_current_span("sqs.receive_messages") as span:
        if not queue_url:
            raise RuntimeError("queue_url is not set")
        response = sqs_client.receive_message(
            QueueUrl=queue_url,
            MaxNumberOfMessages=10,
            WaitTimeSeconds=20,
            MessageAttributeNames=["All"],
            AttributeNames=["All"],
            VisibilityTimeout=60,
        )
        msgs = response.get("Messages", [])
        SQS_POLL_SIZE.observe(len(msgs))
        span.set_attribute("sqs.messages", len(msgs))
        return msgs

def delete_message(receipt_handle: str):
    with tracer.start_as_current_span("sqs.delete_message"):
        try:
            sqs_client.delete_message(QueueUrl=queue_url, ReceiptHandle=receipt_handle)
        except Exception:
            logging.exception("âŒ Failed to delete message")

def process_message(record: dict):
    """ë¹„ì¦ˆ ì²˜ë¦¬"""
    with tracer.start_as_current_span("biz.process_message") as span:
        try:
            body = json.loads(record["Body"]) if isinstance(record.get("Body"), str) else record["Body"]
        except Exception as e:
            logging.exception("âŒ Invalid SQS message body")
            MSG_PROCESSED_TOTAL.labels(result="error").inc()
            span.record_exception(e)
            span.set_status(Status(StatusCode.ERROR, "invalid body"))
            return False

        try:
            message = json.loads(body.get("Message", body)) if isinstance(body.get("Message", body), str) else body.get("Message", body)
        except Exception as e:
            logging.exception("âŒ Invalid nested message (SNS-style)")
            MSG_PROCESSED_TOTAL.labels(result="error").inc()
            span.record_exception(e)
            span.set_status(Status(StatusCode.ERROR, "invalid nested"))
            return False

        user_sub = (message or {}).get("userSub") or body.get("userSub")
        features = (message or {}).get("features") or body.get("features")
        span.set_attribute("user.sub", user_sub or "")
        if features is None:
            logging.warning("âš ï¸ Missing 'features' in message. Skipping.")
            MSG_PROCESSED_TOTAL.labels(result="skipped").inc()
            span.set_status(Status(StatusCode.ERROR, "no features"))
            return False

        try:
            result = invoke_sagemaker(sageMakerEndpoint, features)
            span.set_attribute("model.prediction", result.get("prediction"))
            if result.get("prediction") == 1:
                tokens = get_fcm_tokens(user_sub) if user_sub else []
                publish_sns(tokens)
            MSG_PROCESSED_TOTAL.labels(result="success").inc()
            return True  # ì •ìƒ ì²˜ë¦¬
        except Exception as e:
            logging.exception("âŒ Error during message processing")
            MSG_PROCESSED_TOTAL.labels(result="error").inc()
            span.record_exception(e)
            span.set_status(Status(StatusCode.ERROR, str(e)))
            return False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë©”ì¸ ë£¨í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    # ë¡œê¹…
    logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s [%(name)s] %(message)s")
    _start_health_server()

    # ëˆ„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€(ì—­í•  í™•ì¸)
    try:
        arn = sts_client.get_caller_identity()["Arn"]
        logging.info(f"ğŸ‘¤ STS caller identity: {arn}")
    except Exception as e:
        logging.warning(f"STS whoami failed: {e}")

    logging.info("ğŸš€ SQS receive Worker started")

    # --- ì´ˆê¸°í™” ì¬ì‹œë„ ë£¨í”„ ---
    global initialized
    while not initialized and RUNNING:
        try:
            with tracer.start_as_current_span("bootstrap.init"):
                init()
        except Exception:
            SQS_ERRORS_TOTAL.inc()
        if not initialized:
            time.sleep(5)

    # --- ë©”ì¸ í´ë§ ë£¨í”„ ---
    while RUNNING:
        try:
            with tracer.start_as_current_span("sqs.poll"):
                messages = receive_messages()

            if not messages:
                time.sleep(1)
                continue

            for msg in messages:
                # 1) ë©”ì‹œì§€ì—ì„œ ì»¨í…ìŠ¤íŠ¸ ë³µì›
                ctx = _extract_ctx_from_sqs(msg)

                # 2) ë³µì› ì»¨í…ìŠ¤íŠ¸ë¡œ "ë©”ì‹œì§€ ë‹¨ìœ„" ë£¨íŠ¸ ìŠ¤íŒ¬ ì‹œì‘
                with tracer.start_as_current_span("sqs.process_message", context=ctx) as span:
                    span.set_attribute("sqs.message_id", msg.get("MessageId", ""))
                    ok = process_message(msg)
                    if ok:
                        delete_message(msg.get("ReceiptHandle", ""))

        except Exception:
            logging.exception("Error receiving messages")
            SQS_ERRORS_TOTAL.inc()
            time.sleep(5)

    logging.info("ğŸ‘‹ Exiting main loop.")

if __name__ == "__main__":
    main()
